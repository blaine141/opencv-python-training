{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Core Operations in OpenCV\n",
    "===\n",
    "\n",
    "In which we learn the basic operations and arithmetic operations on images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accessing Image Properties\r\n",
    "\r\n",
    "The shape of an image may be accessed just as we learned with numpy arrays, `image.shape`. It returns a tuple of number of rows, columns, and channels (if the image is not grayscale). The 3 color channels are blue, green, and red in that order."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image = cv2.imread('../assets/windows.jpg')\r\n",
    "\r\n",
    "print(image.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the image is grayscale, it will only return `(ROW, COL)`. Thus, it may be used for checking if an image is grayscale or colored."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the image data type."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(image.dtype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most images will be data type `uint8`. This mean 8-bit unsigned integer which can have values from 0 to 255. A pixel value of 0 is dark and a pixel value of 255 is light."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Access and Modify Pixel Values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can access a pixel value by its row and column coordinates. For RGB image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned. Lets find the pixel value for the top left corner (0, 0) of the windows background from earlier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pixel = image[0, 0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(pixel)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# access only blue pixel\r\n",
    "print(pixel[0])\r\n",
    "\r\n",
    "# access only green pixel\r\n",
    "print(pixel[1])\r\n",
    "\r\n",
    "# access only red pixel\r\n",
    "print(pixel[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, this top left pixel is the sky and is therefore blue. We can see that at this pixel, blue is brighter than green is brighter than red."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Region of Interest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the same way we did numpy slicing before, we can slice images. Lets grab the 100 rightmost columns and display them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Grab the last 100 columns\r\n",
    "# You may have to resize the window\r\n",
    "cropped = image[:, -100:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\r\n",
    "cv2.namedWindow('cropped', cv2.WINDOW_NORMAL)\r\n",
    "cv2.imshow('image', image)\r\n",
    "cv2.imshow('cropped', cropped)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting and Merging Image Channels\n",
    "\n",
    "The RGB channels can be split into their individual planes when needed. It can also be merged to form RGB again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "blue, green, red = cv2.split(image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow('blue_channel', blue)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow('red_channel', red)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow('green_channel', green)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image = cv2.merge((blue, green, red))\r\n",
    "\r\n",
    "cv2.imshow('merged_back', image)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since using `cv2.split()` and `cv2.merge()` are both computationally intensive, we can use NumPy slicing instead."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "blue = image[:, :, 0]\r\n",
    "\r\n",
    "cv2.imshow('blue_channel', blue)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "green = image[:, :, 1]\r\n",
    "\r\n",
    "cv2.imshow('green_channel', green)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "red = image[:, :, 2]\r\n",
    "\r\n",
    "cv2.imshow('red_channel', red)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use NumPy slicing as a way to access an image channel. When we use numpy slicing, the link still exists back to the original image. So here we can zero out the red channel by slicing out the red and setting it to zero."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# modify red channel\r\n",
    "image[:, :, 2] = 0\r\n",
    "\r\n",
    "cv2.imshow('modified_red_channel', image)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without red, everything seems more blue-ish green."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Color Spaces\r\n",
    "\r\n",
    "OpenCV by default represents images in this BGR format (blue, green, red) but there are many other representations. Let's start by converting to grayscale, which is a one channel image. Each pixel value only represents total brightness. This color space is very useful if you do not care about color."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load the windows background\r\n",
    "image = cv2.imread('../assets/windows.jpg')\r\n",
    "\r\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
    "cv2.imshow('gray', image_gray)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we used the cvtColor functions which allows us to convert between color spaces. We can convert back to BGR, but the image will still look gray as we have lost data in the conversion.\r\n",
    "\r\n",
    "Let's convert to a very useful color space, HSV (hue, saturation, value). Hue is the color of the pixel, ranging through the colors of the rainbow (0 - 180), saturation is how colorful the pixel is (0 grayscale - 255 neon), and value is the brightness of the pixel, very similar to grayscale. This color space is very ful when you only care about color. Let's take a peek at the saturation of the windows background and see if it makes sense."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
    "hue, saturation, value = cv2.split(image_hsv)\r\n",
    "\r\n",
    "cv2.imshow('original', image)\r\n",
    "cv2.imshow('saturation', saturation)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resizing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shrink image to 100 x 100 pixels\r\n",
    "image_small = cv2.resize(image, (100, 100))\r\n",
    "\r\n",
    "cv2.imshow('small', image_small)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Thresholding\r\n",
    "\r\n",
    "Thresholding performing an operation on an image based on whether the pixels values are on either side of a threshold. In all out cases, we will do a binary threshold. This means we will use it to turn our image into black an white, 0 and 255, with no in between. Here we will take anything above 200 and turn it into 255 and anything below 200 will be 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1st parameter is input image\r\n",
    "# 2nd parameter is the threshold\r\n",
    "# 3rd parameter is the max value. 255 for uint8\r\n",
    "# 4th parameter is the type of threshold. Binary in our case.\r\n",
    "\r\n",
    "_, image_thresh = cv2.threshold(image_gray, 210, 255, cv2.THRESH_BINARY)\r\n",
    "\r\n",
    "cv2.imshow('threshold', image_thresh)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see why this is useful. We just extracted each of the clouds with one operation. We will be using this a lot in the future."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drawing\r\n",
    "Many times you will have a coordinate in the image but have a hard time visualizing where that is. This is where draing comes in. Lets draw a circle around the coordinate 145, 278."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "center = (145, 278)\r\n",
    "radius = 10\r\n",
    "color = (0, 0, 255)\r\n",
    "thickness = 2\r\n",
    "\r\n",
    "image_annotated = image.copy()\r\n",
    "cv2.circle(image_annotated, center, radius, color, thickness)\r\n",
    "cv2.imshow('annotated', image_annotated)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing Video\r\n",
    "Processing video is as simple as applying operations on each frame as you get it. Let's make the pong video from earlier blue, and then draw a green circle in the center."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(\"../assets/pong.mp4\")\r\n",
    "\r\n",
    "while True:\r\n",
    "    ret, frame = cap.read()\r\n",
    "\r\n",
    "    # if frame is read correctly ret is True\r\n",
    "    if not ret:\r\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\r\n",
    "        break\r\n",
    "\r\n",
    "    # Frame is the current image from the video.\r\n",
    "    # To make the image blue, we can eliminate all the reg and green in the image.\r\n",
    "    frame[:, :, 1] = 0  # Eliminate green \r\n",
    "    frame[:, :, 2] = 0  # Eliminate red\r\n",
    "\r\n",
    "    # To draw a circle in the center, we first need to know how many pixels tall and wide the image is. \r\n",
    "    height, width, channels = frame.shape\r\n",
    "\r\n",
    "    # // is integer division. 5 // 2 = 2\r\n",
    "    center = (width // 2, height // 2)\r\n",
    "    radius = 10\r\n",
    "    color = (0, 255, 0)\r\n",
    "    thickness = 2\r\n",
    "\r\n",
    "    cv2.circle(frame, center, radius, color, thickness)\r\n",
    "    \r\n",
    "    cv2.imshow('Pong.mp4', frame)\r\n",
    "    \r\n",
    "    # If a key was pressed\r\n",
    "    if cv2.waitKey(20) > 0:\r\n",
    "        break\r\n",
    "        \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}